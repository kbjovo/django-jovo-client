"""
Django settings for jovoclient project.

Generated by 'django-admin startproject' using Django 5.2.7.

For more information on this file, see
https://docs.djangoproject.com/en/5.2/topics/settings/

For the full list of settings and their values, see
https://docs.djangoproject.com/en/5.2/ref/settings/
"""

from pathlib import Path
import pymysql
import os
pymysql.install_as_MySQLdb()
import json
import logging
from datetime import datetime
from dotenv import load_dotenv

load_dotenv(".env")

# Build paths inside the project like this: BASE_DIR / 'subdir'.
BASE_DIR = Path(__file__).resolve().parent.parent


# Quick-start development settings - unsuitable for production
# See https://docs.djangoproject.com/en/5.2/howto/deployment/checklist/

# SECURITY WARNING: keep the secret key used in production secret!
SECRET_KEY = os.getenv('SECRET_KEY', 'django-insecure-sd-&4j-s=6t(tj47cyr2fzx2&yn9r5+pu(8#_foh&u@9s8$oqs')

# SECURITY WARNING: don't run with debug turned on in production!
DEBUG = os.getenv('DEBUG', 'True').lower() in ('true', '1', 'yes')




ALLOWED_HOSTS = os.getenv('ALLOWED_HOSTS', 'localhost,127.0.0.1').split(',')


# Application definition

INSTALLED_APPS = [
    'django.contrib.admin',
    'django.contrib.auth',
    'django.contrib.contenttypes',
    'django.contrib.sessions',
    'django.contrib.messages',
    'django.contrib.staticfiles',
    
    #third party app
    'tailwind',
    'theme',
    'django_cotton',
    'django_celery_beat',
    'django_celery_results',
    'django_prometheus',
   
    # local app
    'client',
    
]


if DEBUG:
    # Add django_browser_reload only in DEBUG mode
    INSTALLED_APPS += ['django_browser_reload']
    


MIDDLEWARE = [    
    'django_prometheus.middleware.PrometheusBeforeMiddleware',
    'django.middleware.security.SecurityMiddleware',
    'django.contrib.sessions.middleware.SessionMiddleware',
    'django.middleware.common.CommonMiddleware',
    'django.middleware.csrf.CsrfViewMiddleware',
    'django.contrib.auth.middleware.AuthenticationMiddleware',
    'django.contrib.messages.middleware.MessageMiddleware',
    'django.middleware.clickjacking.XFrameOptionsMiddleware',
    'django_prometheus.middleware.PrometheusAfterMiddleware',
    
]


if DEBUG:
    # Add django_browser_reload middleware only in DEBUG mode
    MIDDLEWARE += [
        "django_browser_reload.middleware.BrowserReloadMiddleware",
    ]
    

ROOT_URLCONF = 'jovoclient.urls'

TEMPLATES = [
    {
        'BACKEND': 'django.template.backends.django.DjangoTemplates',
        'DIRS': [BASE_DIR / 'templates'],
        'APP_DIRS': True,
        'OPTIONS': {
            'context_processors': [
                'django.template.context_processors.request',
                'django.contrib.auth.context_processors.auth',
                'django.contrib.messages.context_processors.messages',
            ],
        },
    },
]

WSGI_APPLICATION = 'jovoclient.wsgi.application'



DATABASES = {
    'default': {
        'ENGINE': 'django_prometheus.db.backends.mysql',  # Changed from django.db.backends.mysql
        'NAME': os.getenv('DB_NAME', 'client'),
        'USER': os.getenv('DB_USER', 'root'),
        'PASSWORD': os.getenv('DB_PASSWORD', 'root'),
        'HOST': os.getenv('DB_HOST', 'localhost'),
        'PORT': os.getenv('DB_PORT', '3306'),
        'CONN_MAX_AGE': 600,
    }
}

PROMETHEUS_METRIC_NAMESPACE = 'jovoclient'

PROMETHEUS_LATENCY_BUCKETS = (
    0.1, 0.25, 0.5, 0.75, 1.0,      # Fast queries (< 1s)
    2.0, 3.0, 5.0, 7.5, 10.0,       # Medium queries (1-10s)
    15.0, 30.0, 60.0, 120.0, 300.0, # Slow queries (1-5 min)
    float("inf")
)

PROMETHEUS_EXPORT_MIGRATIONS = False


# Password validation
# https://docs.djangoproject.com/en/5.2/ref/settings/#auth-password-validators

AUTH_PASSWORD_VALIDATORS = [
    {
        'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.NumericPasswordValidator',
    },
]


# Internationalization
# https://docs.djangoproject.com/en/5.2/topics/i18n/

LANGUAGE_CODE = 'en-us'

TIME_ZONE = 'UTC'

USE_I18N = True

USE_TZ = True


# Static files (CSS, JavaScript, Images)
# https://docs.djangoproject.com/en/5.2/howto/static-files/

STATIC_URL = 'static/'

TAILWIND_APP_NAME = 'theme'

NPM_BIN_PATH = os.getenv("NPM_BIN_PATH","/usr/local/bin/npm")




# Default primary key field type
# https://docs.djangoproject.com/en/5.2/ref/settings/#default-auto-field

DEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'
DATA_UPLOAD_MAX_NUMBER_FIELDS = 1000000
# Database password encryption key (symmetric encryption)
# TODO: Move this to environment variable in production
DB_PASSWORD_ENCRYPTION_KEY = 'your-32-byte-encryption-key-change-this-in-production!!'


# Email Configuration
EMAIL_BACKEND = 'django.core.mail.backends.smtp.EmailBackend'
EMAIL_HOST = 'smtp.gmail.com'  # Your SMTP server
EMAIL_PORT = 587
EMAIL_USE_TLS = True
EMAIL_HOST_USER = 'jovo@kaybeebio.com'
EMAIL_HOST_PASSWORD = 'dchj gcgb hbgh xraf'
DEFAULT_FROM_EMAIL = 'noreply@yourcompany.com'

# Admin emails for error notifications
ADMINS = [
    ('Admin', 'jovo@kaybeebio.com'),
    ('Dev Team', 'dev@example.com'),
]

# Environment identifier
ENVIRONMENT = 'development'  # or 'staging', 'production'



# Custom JSON formatter for structured logging
class JSONFormatter(logging.Formatter):
    """
    Custom formatter that outputs logs in JSON format for Loki
    """
    def format(self, record):
        log_data = {
            'timestamp': datetime.utcnow().isoformat() + 'Z',
            'level': record.levelname,
            'logger': record.name,
            'message': record.getMessage(),
            'module': record.module,
            'function': record.funcName,
            'line': record.lineno,
        }
        
        # Add exception info if present
        if record.exc_info:
            log_data['exception'] = self.formatException(record.exc_info)
        
        # Add extra fields if present
        if hasattr(record, 'client_id'):
            log_data['client_id'] = record.client_id
        if hasattr(record, 'connector_name'):
            log_data['connector_name'] = record.connector_name
        if hasattr(record, 'table_name'):
            log_data['table_name'] = record.table_name
        if hasattr(record, 'operation'):
            log_data['operation'] = record.operation
        if hasattr(record, 'duration'):
            log_data['duration_seconds'] = record.duration
            
        return json.dumps(log_data)


LOGGING = {
    'version': 1,
    'disable_existing_loggers': False,
    
    'formatters': {
        # JSON formatter for production/monitoring
        'json': {
            '()': JSONFormatter,
        },
        # Human-readable formatter for console during development
        'verbose': {
            'format': '[{levelname}] {asctime} {name} {module}.{funcName}:{lineno} - {message}',
            'style': '{',
            'datefmt': '%Y-%m-%d %H:%M:%S',
        },
        # Simple formatter for console
        'simple': {
            'format': '[{levelname}] {name} - {message}',
            'style': '{',
        },
    },
    
    'filters': {
        'require_debug_false': {
            '()': 'django.utils.log.RequireDebugFalse',
        },
        'require_debug_true': {
            '()': 'django.utils.log.RequireDebugTrue',
        },
    },
    
    'handlers': {
        # Console output - human readable for development
        'console': {
            'level': 'INFO',
            'class': 'logging.StreamHandler',
            'formatter': 'verbose',
        },
        
        # JSON file - for Promtail to collect
        'json_file': {
            'level': 'INFO',
            'class': 'logging.handlers.TimedRotatingFileHandler',
            'filename': 'logs/application.json',
            'when': 'H',              # Rotate every hour
            'interval': 1,
            'backupCount': 48,        # Keep 48 hours
            'formatter': 'json',
            'encoding': 'utf-8',
        },
        
        # Standard file - for backward compatibility
        'file': {
            'level': 'INFO',
            'class': 'logging.handlers.TimedRotatingFileHandler',
            'filename': 'logs/replication.log',
            'when': 'H',
            'interval': 1,
            'backupCount': 48,
            'formatter': 'verbose',
            'encoding': 'utf-8',
        },
        
        # Error-only file - JSON format
        'error_json_file': {
            'level': 'ERROR',
            'class': 'logging.handlers.TimedRotatingFileHandler',
            'filename': 'logs/errors.json',
            'when': 'D',              # Daily rotation for errors
            'interval': 1,
            'backupCount': 30,        # Keep 30 days
            'formatter': 'json',
            'encoding': 'utf-8',
        },
        
        # Celery task logs - JSON format
        'celery_json_file': {
            'level': 'INFO',
            'class': 'logging.handlers.TimedRotatingFileHandler',
            'filename': 'logs/celery.json',
            'when': 'H',
            'interval': 1,
            'backupCount': 48,
            'formatter': 'json',
            'encoding': 'utf-8',
        },
        
        # CDC-specific logs - JSON format
        'cdc_json_file': {
            'level': 'INFO',
            'class': 'logging.handlers.TimedRotatingFileHandler',
            'filename': 'logs/cdc.json',
            'when': 'H',
            'interval': 1,
            'backupCount': 72,        # Keep 3 days for CDC logs
            'formatter': 'json',
            'encoding': 'utf-8',
        },
    },
    
    'loggers': {
        # Root logger - catches everything
        '': {
            'handlers': ['console', 'json_file', 'error_json_file'],
            'level': 'INFO',
            'propagate': True,
        },
        
        # Django framework logs
        'django': {
            'handlers': ['console', 'json_file'],
            'level': 'INFO',
            'propagate': False,
        },
        
        # Django database queries (set to WARNING to reduce noise)
        'django.db.backends': {
            'handlers': ['console'],
            'level': 'WARNING',
            'propagate': False,
        },
        
        # Django request logs
        'django.request': {
            'handlers': ['console', 'json_file', 'error_json_file'],
            'level': 'INFO',
            'propagate': False,
        },
        
        # Celery logs
        'celery': {
            'handlers': ['console', 'celery_json_file', 'error_json_file'],
            'level': 'INFO',
            'propagate': False,
        },
        
        # Your application logs
        'client': {
            'handlers': ['console', 'json_file', 'error_json_file'],
            'level': 'INFO',
            'propagate': False,
        },
        
        # CDC-specific logger
        'client.cdc': {
            'handlers': ['console', 'cdc_json_file', 'error_json_file'],
            'level': 'INFO',
            'propagate': False,
        },
        
        # Kafka/Debezium logs
        'client.kafka': {
            'handlers': ['console', 'cdc_json_file', 'error_json_file'],
            'level': 'INFO',
            'propagate': False,
        },
        
        # Database operations
        'client.database': {
            'handlers': ['console', 'json_file', 'error_json_file'],
            'level': 'INFO',
            'propagate': False,
        },
    },
}



# ====================================
# CELERY CONFIGURATION - FIXED FOR IDLE TIMEOUT
# ====================================
CELERY_BROKER_URL = os.getenv('CELERY_BROKER_URL', 'redis://localhost:6379/0')
CELERY_RESULT_BACKEND = os.getenv('CELERY_RESULT_BACKEND', 'redis://localhost:6379/0')
CELERY_ACCEPT_CONTENT = ['json']
CELERY_TASK_SERIALIZER = 'json'
CELERY_RESULT_SERIALIZER = 'json'
CELERY_TIMEZONE = 'Asia/Kolkata'
CELERY_TASK_TRACK_STARTED = True

# Broker connection retry settings
CELERY_BROKER_CONNECTION_RETRY_ON_STARTUP = True
CELERY_BROKER_CONNECTION_RETRY = True
CELERY_BROKER_CONNECTION_MAX_RETRIES = 10

# Global visibility timeout (set all three for Redis)
CELERY_VISIBILITY_TIMEOUT = int(os.getenv('CELERY_VISIBILITY_TIMEOUT', '43200'))  # 12 hours

# Task execution time limits
CELERY_TASK_TIME_LIMIT = int(os.getenv('CELERY_TASK_TIME_LIMIT', '7200'))  # 2 hours hard limit
CELERY_TASK_SOFT_TIME_LIMIT = int(os.getenv('CELERY_TASK_SOFT_TIME_LIMIT', '6900'))  # 1h 55m soft limit

# Worker prefetch settings
CELERY_WORKER_PREFETCH_MULTIPLIER = int(os.getenv('CELERY_WORKER_PREFETCH_MULTIPLIER', '1'))

# Worker max tasks per child (prevents memory leaks)
CELERY_WORKER_MAX_TASKS_PER_CHILD = int(os.getenv('CELERY_WORKER_MAX_TASKS_PER_CHILD', '1000'))

# Task acknowledgment settings
CELERY_TASK_ACKS_LATE = os.getenv('CELERY_TASK_ACKS_LATE', 'True').lower() in ('true', '1', 'yes')
CELERY_TASK_REJECT_ON_WORKER_LOST = os.getenv('CELERY_TASK_REJECT_ON_WORKER_LOST', 'True').lower() in ('true', '1', 'yes')

# Connection loss handling
CELERY_WORKER_CANCEL_LONG_RUNNING_TASKS_ON_CONNECTION_LOSS = os.getenv(
    'CELERY_WORKER_CANCEL_LONG_RUNNING_TASKS', 
    'False'
).lower() in ('true', '1', 'yes')

# Enable prefetch count reduction after connection loss (Celery 5.4+)
CELERY_WORKER_ENABLE_PREFETCH_COUNT_REDUCTION = True

# Result settings
CELERY_RESULT_EXPIRES = int(os.getenv('CELERY_RESULT_EXPIRES', '86400'))  # 1 day
CELERY_RESULT_EXTENDED = True
CELERY_RESULT_COMPRESSION = 'gzip'

# Celery Beat
CELERY_BEAT_SCHEDULER = 'django_celery_beat.schedulers:DatabaseScheduler'
CELERY_BEAT_MAX_LOOP_INTERVAL = 60  # 1 minute

# Monitoring and events
CELERY_TASK_SEND_SENT_EVENT = True
CELERY_EVENT_QUEUE_EXPIRES = 60  # 1 minute
CELERY_EVENT_QUEUE_TTL = 5  # 5 seconds
CELERY_WORKER_STATE_DB = '/tmp/celery_worker_state.db'

# Task routing
CELERY_TASK_ROUTES = {
    'client.tasks.consumer_tasks.*': {
        'queue': 'consumers',
        'routing_key': 'consumers',
    },
    'client.tasks.general_tasks.*': {
        'queue': 'celery',
        'routing_key': 'celery',
    },
}

# Default queue
CELERY_TASK_DEFAULT_QUEUE = 'celery'
CELERY_TASK_DEFAULT_EXCHANGE = 'celery'
CELERY_TASK_DEFAULT_ROUTING_KEY = 'celery'

# Additional optimizations
CELERY_CACHE_BACKEND = None
CELERY_TASK_COMPRESSION = 'gzip'
CELERY_MESSAGE_COMPRESSION = 'gzip'
CELERY_WORKER_POOL = 'prefork'
CELERY_WORKER_CONCURRENCY = int(os.getenv('CELERY_WORKER_CONCURRENCY', '4'))
CELERY_WORKER_DISABLE_RATE_LIMITS = os.getenv('CELERY_DISABLE_RATE_LIMITS', 'False').lower() in ('true', '1', 'yes')

# ====================================
# DEBEZIUM / KAFKA CONFIGURATION
# ====================================
DEBEZIUM_CONFIG = {
    'KAFKA_CONNECT_URL': os.getenv('KAFKA_CONNECT_URL', 'http://localhost:8083'),
    
    # External bootstrap servers (for host machine connections)
    'KAFKA_BOOTSTRAP_SERVERS': os.getenv(
        'KAFKA_BOOTSTRAP_SERVERS', 
        'localhost:9092,localhost:9094,localhost:9096'
    ),
    
    # Internal bootstrap servers (for Docker container communication)
    'KAFKA_INTERNAL_SERVERS': os.getenv(
        'KAFKA_INTERNAL_SERVERS', 
        'kafka-1:29092,kafka-2:29092,kafka-3:29092'
    ),
    
    'SCHEMA_REGISTRY_URL': os.getenv('SCHEMA_REGISTRY_URL', 'http://localhost:8082'),
    'CONSUMER_GROUP_PREFIX': 'cdc_consumer',
}

# ====================================
# KAFKA TOPIC CONFIGURATION
# ====================================
KAFKA_TOPIC_CONFIG = {
    'PARTITIONS': int(os.getenv('KAFKA_TOPIC_PARTITIONS', '1')),
    'REPLICATION_FACTOR': int(os.getenv('KAFKA_TOPIC_REPLICATION_FACTOR', '3')),  # Updated for 3 brokers
    'RETENTION_MS': int(os.getenv('KAFKA_TOPIC_RETENTION_MS', '604800000')),  # 7 days
    'RETENTION_BYTES': int(os.getenv('KAFKA_TOPIC_RETENTION_BYTES', '-1')),
    'CLEANUP_POLICY': os.getenv('KAFKA_TOPIC_CLEANUP_POLICY', 'delete'),
    'COMPRESSION_TYPE': os.getenv('KAFKA_TOPIC_COMPRESSION_TYPE', 'snappy'),
    'MIN_INSYNC_REPLICAS': int(os.getenv('KAFKA_TOPIC_MIN_ISR', '2')),  # Updated for 3 brokers
    'SEGMENT_BYTES': int(os.getenv('KAFKA_TOPIC_SEGMENT_BYTES', '1073741824')),
    'SEGMENT_MS': int(os.getenv('KAFKA_TOPIC_SEGMENT_MS', '604800000')),
}

# ====================================
# KAFKA ADMIN CONFIGURATION
# ====================================
KAFKA_ADMIN_CONFIG = {
    'REQUEST_TIMEOUT_MS': int(os.getenv('KAFKA_ADMIN_REQUEST_TIMEOUT_MS', '30000')),
    'API_VERSION_AUTO_TIMEOUT_MS': int(os.getenv('KAFKA_ADMIN_API_VERSION_TIMEOUT_MS', '30000')),
    'METADATA_MAX_AGE_MS': int(os.getenv('KAFKA_ADMIN_METADATA_MAX_AGE_MS', '300000')),
    'AUTO_CREATE_TOPICS': False,  # Must be False since brokers have auto-create disabled
    'TOPIC_CREATE_RETRIES': int(os.getenv('KAFKA_TOPIC_CREATE_RETRIES', '3')),
    'TOPIC_CREATE_RETRY_BACKOFF_MS': int(os.getenv('KAFKA_TOPIC_CREATE_RETRY_BACKOFF_MS', '1000')),
}

# ====================================
# KAFKA CONSUMER CONFIGURATION
# ====================================
KAFKA_CONSUMER_CONFIG = {
    'SESSION_TIMEOUT_MS': int(os.getenv('KAFKA_CONSUMER_SESSION_TIMEOUT_MS', '30000')),
    'HEARTBEAT_INTERVAL_MS': int(os.getenv('KAFKA_CONSUMER_HEARTBEAT_INTERVAL_MS', '10000')),
    'MAX_POLL_INTERVAL_MS': int(os.getenv('KAFKA_CONSUMER_MAX_POLL_INTERVAL_MS', '300000')),
    'MAX_POLL_RECORDS': int(os.getenv('KAFKA_CONSUMER_MAX_POLL_RECORDS', '500')),
    'AUTO_OFFSET_RESET': os.getenv('KAFKA_CONSUMER_AUTO_OFFSET_RESET', 'earliest'),
    'ENABLE_AUTO_COMMIT': os.getenv('KAFKA_CONSUMER_ENABLE_AUTO_COMMIT', 'False').lower() in ('true', '1', 'yes'),
    'AUTO_COMMIT_INTERVAL_MS': int(os.getenv('KAFKA_CONSUMER_AUTO_COMMIT_INTERVAL_MS', '5000')),
}

# ====================================
# KAFKA PRODUCER CONFIGURATION
# ====================================
KAFKA_PRODUCER_CONFIG = {
    'ACKS': os.getenv('KAFKA_PRODUCER_ACKS', 'all'),  # Wait for all replicas
    'RETRIES': int(os.getenv('KAFKA_PRODUCER_RETRIES', '3')),
    'RETRY_BACKOFF_MS': int(os.getenv('KAFKA_PRODUCER_RETRY_BACKOFF_MS', '1000')),
    'BATCH_SIZE': int(os.getenv('KAFKA_PRODUCER_BATCH_SIZE', '16384')),
    'LINGER_MS': int(os.getenv('KAFKA_PRODUCER_LINGER_MS', '10')),
    'COMPRESSION_TYPE': os.getenv('KAFKA_PRODUCER_COMPRESSION_TYPE', 'snappy'),
    'MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION': int(os.getenv('KAFKA_PRODUCER_MAX_IN_FLIGHT', '5')),
    'REQUEST_TIMEOUT_MS': int(os.getenv('KAFKA_PRODUCER_REQUEST_TIMEOUT_MS', '30000')),
}