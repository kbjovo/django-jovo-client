services:
  # Kafka Broker 1 (KRaft mode)
  kafka-1:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka-1
    hostname: kafka-1
    ports:
      - "9092:9092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka-1:9093,2@kafka-2:9093,3@kafka-3:9093"
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENERS: "PLAINTEXT://kafka-1:29092,PLAINTEXT_HOST://0.0.0.0:9092,CONTROLLER://kafka-1:9093"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka-1:29092,PLAINTEXT_HOST://localhost:9092"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT"
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      CLUSTER_ID: "MkU3OEVBNTcwNTJENDM2Qk"
    volumes:
      - kafka1-data:/var/lib/kafka/data
    networks:
      - replication-network
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 10s
      timeout: 10s
      retries: 10
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 2G
    restart: unless-stopped
    command: >
      bash -c "
      if [ ! -f /var/lib/kafka/data/meta.properties ]; then
        kafka-storage format -t MkU3OEVBNTcwNTJENDM2Qk -c /etc/kafka/kafka.properties;
      fi;
      /etc/confluent/docker/run
      "

  kafka-2:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka-2
    hostname: kafka-2
    ports:
      - "9094:9092"
    environment:
      KAFKA_NODE_ID: 2
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka-1:9093,2@kafka-2:9093,3@kafka-3:9093"
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENERS: "PLAINTEXT://kafka-2:29092,PLAINTEXT_HOST://0.0.0.0:9092,CONTROLLER://kafka-2:9093"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka-2:29092,PLAINTEXT_HOST://localhost:9094"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT"
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      CLUSTER_ID: "MkU3OEVBNTcwNTJENDM2Qk"
    volumes:
      - kafka2-data:/var/lib/kafka/data
    networks:
      - replication-network
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 10s
      timeout: 10s
      retries: 10
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 2G
    restart: unless-stopped
    command: >
      bash -c "
      if [ ! -f /var/lib/kafka/data/meta.properties ]; then
        kafka-storage format -t MkU3OEVBNTcwNTJENDM2Qk -c /etc/kafka/kafka.properties;
      fi;
      /etc/confluent/docker/run
      "

  kafka-3:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka-3
    hostname: kafka-3
    ports:
      - "9096:9092"
    environment:
      KAFKA_NODE_ID: 3
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka-1:9093,2@kafka-2:9093,3@kafka-3:9093"
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENERS: "PLAINTEXT://kafka-3:29092,PLAINTEXT_HOST://0.0.0.0:9092,CONTROLLER://kafka-3:9093"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka-3:29092,PLAINTEXT_HOST://localhost:9096"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT"
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      CLUSTER_ID: "MkU3OEVBNTcwNTJENDM2Qk"
    volumes:
      - kafka3-data:/var/lib/kafka/data
    networks:
      - replication-network
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 10s
      timeout: 10s
      retries: 10
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 2G
    restart: unless-stopped
    command: >
      bash -c "
      if [ ! -f /var/lib/kafka/data/meta.properties ]; then
        kafka-storage format -t MkU3OEVBNTcwNTJENDM2Qk -c /etc/kafka/kafka.properties;
      fi;
      /etc/confluent/docker/run
      "

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    depends_on:
      kafka-1:
        condition: service_healthy
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local-cluster
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka-1:29092,kafka-2:29092,kafka-3:29092
      KAFKA_CLUSTERS_0_SCHEMAREGISTRY: http://schema-registry:8081
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_NAME: connect
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_ADDRESS: http://kafka-connect:8083
    networks:
      - replication-network
    restart: unless-stopped

  schema-registry:
    image: confluentinc/cp-schema-registry:7.5.0
    container_name: schema-registry
    hostname: schema-registry
    depends_on:
      kafka-1:
        condition: service_healthy
    ports:
      - "8082:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: kafka-1:29092,kafka-2:29092,kafka-3:29092
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
      SCHEMA_REGISTRY_KAFKASTORE_TIMEOUT_MS: 10000
      SCHEMA_REGISTRY_KAFKASTORE_INIT_TIMEOUT_MS: 120000
      SCHEMA_REGISTRY_KAFKASTORE_TOPIC: _schemas
      SCHEMA_REGISTRY_KAFKASTORE_TOPIC_REPLICATION_FACTOR: 3
    networks:
      - replication-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/"]
      interval: 10s
      timeout: 10s
      retries: 10
      start_period: 120s
    restart: unless-stopped

  kafka-connect:
    build:
      context: .
      dockerfile: Dockerfile.kafka-connect
    image: kafka-connect-debezium:latest
    container_name: kafka-connect
    hostname: kafka-connect
    depends_on:
      kafka-1:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
    ports:
      - "8083:8083"    # Kafka Connect REST API
      - "8778:8778"    # Jolokia JMX HTTP endpoint
    environment:
      BOOTSTRAP_SERVERS: kafka-1:29092,kafka-2:29092,kafka-3:29092
      GROUP_ID: connect-cluster
      CONFIG_STORAGE_TOPIC: connect-configs
      OFFSET_STORAGE_TOPIC: connect-offsets
      STATUS_STORAGE_TOPIC: connect-statuses
      CONFIG_STORAGE_REPLICATION_FACTOR: 3
      OFFSET_STORAGE_REPLICATION_FACTOR: 3
      STATUS_STORAGE_REPLICATION_FACTOR: 3
      KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
      VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      KAFKA_HEAP_OPTS: "-Xms4G -Xmx4G"
      CONNECT_PLUGIN_PATH: /kafka/connect
    # ============================================
    # VOLUMES - Mount Jolokia JAR from host
    # ============================================
    volumes:
      - ./jolokia/jolokia-jvm-agent.jar:/opt/jolokia/jolokia-jvm-agent.jar:ro

    # ============================================
    # DOCKER LOGGING DRIVER CONFIGURATION
    # ============================================
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "5"
        labels: "service=kafka-connect,component=debezium"

    networks:
      - replication-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8083/"]
      interval: 10s
      timeout: 10s
      retries: 20
      start_period: 120s
    restart: unless-stopped

  # ============================================
  # Django Web Application
  # ============================================
  django:
    build:
      context: ..
      dockerfile: Dockerfile
    container_name: django
    hostname: django
    depends_on:
      mysql:
        condition: service_healthy
      redis:
        condition: service_healthy
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy
    ports:
      - "8000:8000"
    environment:
      - DJANGO_SETTINGS_MODULE=jovoclient.settings
    env_file:
      - ../.env.docker
    volumes:
      - ..:/app
      - django-static:/app/staticfiles
      - django-media:/app/mediafiles
      - ../logs:/app/logs
    networks:
      - replication-network
    command: python manage.py runserver 0.0.0.0:8000
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8000/ || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s
    restart: unless-stopped

  # ============================================
  # Celery Worker - Task Executor
  # ============================================
  celery-worker:
    build:
      context: ..
      dockerfile: Dockerfile
    container_name: celery-worker
    hostname: celery-worker
    depends_on:
      - django
      - redis
    environment:
      - DJANGO_SETTINGS_MODULE=jovoclient.settings
    env_file:
      - ../.env.docker
    volumes:
      - ..:/app
      - ../logs:/app/logs
    networks:
      - replication-network
    command: celery -A jovoclient worker -l info -c 4 --max-tasks-per-child=100
    deploy:
      resources:
        limits:
          memory: 1G
    restart: unless-stopped

  # ============================================
  # Celery DDL Consumer - Real-time DDL Sync
  # ============================================
  celery-ddl-consumer:
    build:
      context: ..
      dockerfile: Dockerfile
    container_name: celery-ddl-consumer
    hostname: celery-ddl-consumer
    depends_on:
      - django
      - redis
      - kafka-1
    environment:
      - DJANGO_SETTINGS_MODULE=jovoclient.settings
    env_file:
      - ../.env.docker
    volumes:
      - ..:/app
      - ../logs:/app/logs
      - /app/.venv
    networks:
      - replication-network
    command: celery -A jovoclient worker -l debug -Q ddl_consumer -P solo
    deploy:
      resources:
        limits:
          memory: 512M
    restart: unless-stopped

  # ============================================
  # Celery Beat - Periodic Tasks Scheduler
  # ============================================
  celery-beat:
    build:
      context: ..
      dockerfile: Dockerfile
    container_name: celery-beat
    hostname: celery-beat
    depends_on:
      - django
      - redis
      - celery-worker
    environment:
      - DJANGO_SETTINGS_MODULE=jovoclient.settings
    env_file:
      - ../.env.docker
    volumes:
      - ..:/app
      - ../logs:/app/logs
    networks:
      - replication-network
    command: celery -A jovoclient beat -l info
    restart: unless-stopped


=======
>>>>>>> 00ad81b (Commit from github)
volumes:
  kafka1-data:
  kafka2-data:
  kafka3-data:

networks:
  replication-network:
    driver: bridge
    name: replication-network
