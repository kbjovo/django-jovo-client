services:
  # ============================================
  # MySQL Database
  # ============================================
  mysql:
    image: mysql:8.0
    container_name: mysql_wsl
    hostname: mysql
    command:
      - --server-id=1
      - --log-bin=mysql-bin
      - --binlog-format=ROW
      - --binlog-row-image=FULL
      - --binlog-expire-logs-seconds=259200
      - --default-authentication-plugin=mysql_native_password
      - --bind-address=0.0.0.0
      - --max-connections=500
      - --gtid-mode=ON
      - --enforce-gtid-consistency=ON
    environment:
      MYSQL_ROOT_PASSWORD: root
      MYSQL_DATABASE: client
      MYSQL_USER: jovo_test
      MYSQL_PASSWORD: root
    ports:
      - "3306:3306"
    volumes:
      - mysql-data:/var/lib/mysql
    networks:
      - replication-network
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "-u", "root", "-proot"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # ============================================
  # Redis - WITH FIXES FOR CELERY IDLE ISSUES
  # ============================================
  redis:
    image: redis:7-alpine
    container_name: redis
    hostname: redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    networks:
      - replication-network
    command: redis-server --appendonly yes --bind 0.0.0.0 --protected-mode no
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
    restart: unless-stopped

  # ============================================
  # Kafka Broker 1 (KRaft mode)
  # ============================================
  kafka-1:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka-1
    hostname: kafka-1
    ports:
      - "9092:9092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka-1:9093,2@kafka-2:9093,3@kafka-3:9093"
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENERS: "PLAINTEXT://kafka-1:29092,PLAINTEXT_HOST://0.0.0.0:9092,CONTROLLER://kafka-1:9093"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka-1:29092,PLAINTEXT_HOST://localhost:9092"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT"
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      CLUSTER_ID: "MkU3OEVBNTcwNTJENDM2Qk"
    volumes:
      - kafka1-data:/var/lib/kafka/data
    networks:
      - replication-network
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 10s
      timeout: 10s
      retries: 10
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1'
        reservations:
          memory: 1G
    restart: unless-stopped
    command: >
      bash -c "
      if [ ! -f /var/lib/kafka/data/meta.properties ]; then
        kafka-storage format -t MkU3OEVBNTcwNTJENDM2Qk -c /etc/kafka/kafka.properties;
      fi;
      /etc/confluent/docker/run
      "

  # ============================================
  # Kafka Broker 2 (KRaft mode)
  # ============================================
  kafka-2:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka-2
    hostname: kafka-2
    ports:
      - "9094:9092"
    environment:
      KAFKA_NODE_ID: 2
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka-1:9093,2@kafka-2:9093,3@kafka-3:9093"
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENERS: "PLAINTEXT://kafka-2:29092,PLAINTEXT_HOST://0.0.0.0:9092,CONTROLLER://kafka-2:9093"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka-2:29092,PLAINTEXT_HOST://localhost:9094"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT"
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      CLUSTER_ID: "MkU3OEVBNTcwNTJENDM2Qk"
    volumes:
      - kafka2-data:/var/lib/kafka/data
    networks:
      - replication-network
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 10s
      timeout: 10s
      retries: 10
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1'
        reservations:
          memory: 1G
    restart: unless-stopped
    command: >
      bash -c "
      if [ ! -f /var/lib/kafka/data/meta.properties ]; then
        kafka-storage format -t MkU3OEVBNTcwNTJENDM2Qk -c /etc/kafka/kafka.properties;
      fi;
      /etc/confluent/docker/run
      "

  # ============================================
  # Kafka Broker 3 (KRaft mode)
  # ============================================
  kafka-3:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka-3
    hostname: kafka-3
    ports:
      - "9096:9092"
    environment:
      KAFKA_NODE_ID: 3
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka-1:9093,2@kafka-2:9093,3@kafka-3:9093"
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENERS: "PLAINTEXT://kafka-3:29092,PLAINTEXT_HOST://0.0.0.0:9092,CONTROLLER://kafka-3:9093"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka-3:29092,PLAINTEXT_HOST://localhost:9096"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT"
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      CLUSTER_ID: "MkU3OEVBNTcwNTJENDM2Qk"
    volumes:
      - kafka3-data:/var/lib/kafka/data
    networks:
      - replication-network
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 10s
      timeout: 10s
      retries: 10
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1'
        reservations:
          memory: 1G
    restart: unless-stopped
    command: >
      bash -c "
      if [ ! -f /var/lib/kafka/data/meta.properties ]; then
        kafka-storage format -t MkU3OEVBNTcwNTJENDM2Qk -c /etc/kafka/kafka.properties;
      fi;
      /etc/confluent/docker/run
      "

  # ============================================
  # Kafka UI - Web Interface
  # ============================================
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    depends_on:
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local-cluster
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka-1:29092,kafka-2:29092,kafka-3:29092
      KAFKA_CLUSTERS_0_SCHEMAREGISTRY: http://schema-registry:8081
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_NAME: connect
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_ADDRESS: http://kafka-connect:8083
      DYNAMIC_CONFIG_ENABLED: 'true'
    networks:
      - replication-network
    restart: unless-stopped

  # ============================================
  # Schema Registry
  # ============================================
  schema-registry:
    image: confluentinc/cp-schema-registry:7.5.0
    container_name: schema-registry
    hostname: schema-registry
    depends_on:
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy
    ports:
      - "8082:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: kafka-1:29092,kafka-2:29092,kafka-3:29092
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
      SCHEMA_REGISTRY_LOG4J_ROOT_LOGLEVEL: WARN
      
      # CRITICAL FIXES FOR KRAFT:
      # Increase timeout for multi-broker KRaft clusters
      SCHEMA_REGISTRY_KAFKASTORE_TIMEOUT_MS: 10000
      SCHEMA_REGISTRY_KAFKASTORE_INIT_TIMEOUT_MS: 120000
      
      # Consumer/Producer settings for better connectivity
      SCHEMA_REGISTRY_KAFKASTORE_SECURITY_PROTOCOL: PLAINTEXT
      
      # Schema registry topic settings
      SCHEMA_REGISTRY_KAFKASTORE_TOPIC: _schemas
      SCHEMA_REGISTRY_KAFKASTORE_TOPIC_REPLICATION_FACTOR: 3
      
      # Debug setting (optional - remove in production)
      SCHEMA_REGISTRY_DEBUG: "false"
      
    networks:
      - replication-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/"]
      interval: 10s
      timeout: 10s
      retries: 10
      start_period: 120s  # CRITICAL: Wait 2 minutes before checking health
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 512M
    restart: unless-stopped

  # ============================================
  # Kafka Connect (Confluent + Debezium plugins)
  # ============================================
  # ============================================
  # Kafka Connect (Debezium 3.3 + Confluent Avro Converter)
  # WITH CONSOLE LOGGING ENABLED
  # ============================================
  kafka-connect:
    build:
      context: .
      dockerfile: Dockerfile.kafka-connect
    image: kafka-connect-debezium:latest
    container_name: kafka-connect
    hostname: kafka-connect
    depends_on:
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
      mysql:
        condition: service_healthy
    ports:
      - "8083:8083"
    environment:
      # Kafka Bootstrap Servers
      BOOTSTRAP_SERVERS: kafka-1:29092,kafka-2:29092,kafka-3:29092
      
      # Connect Cluster Configuration
      GROUP_ID: connect-cluster
      CONFIG_STORAGE_TOPIC: connect-configs
      OFFSET_STORAGE_TOPIC: connect-offsets
      STATUS_STORAGE_TOPIC: connect-statuses
      
      # Replication Factors
      CONFIG_STORAGE_REPLICATION_FACTOR: 3
      OFFSET_STORAGE_REPLICATION_FACTOR: 3
      STATUS_STORAGE_REPLICATION_FACTOR: 3
      
      # Key/Value Converters
      KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
      VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      
      # Internal Converters
      INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      
      # Performance Tuning
      CONNECT_TASK_SHUTDOWN_GRACEFUL_TIMEOUT_MS: 30000
      CONNECT_PRODUCER_BATCH_SIZE: 32768
      CONNECT_PRODUCER_LINGER_MS: 10
      CONNECT_PRODUCER_BUFFER_MEMORY: 67108864
      CONNECT_PRODUCER_MAX_REQUEST_SIZE: 10485760
      CONNECT_PRODUCER_COMPRESSION_TYPE: lz4
      CONNECT_CONSUMER_MAX_POLL_RECORDS: 1000
      CONNECT_CONSUMER_FETCH_MIN_BYTES: 1048576
      
      # JVM Heap Settings (configurable via .env.docker)
      KAFKA_HEAP_OPTS: "${KAFKA_CONNECT_HEAP_OPTS:--Xms4G -Xmx4G}"
      
      # ============================================
      # CRITICAL LOGGING CONFIGURATION
      # Force all logs to stdout/stderr for Docker (Log4j2 format)
      # ============================================
      KAFKA_LOG4J_OPTS: "-Dlog4j2.configurationFile=file:/kafka/config/log4j2.properties"
      CONNECT_LOG4J_ROOT_LOGLEVEL: INFO
      
      # Additional Debezium settings
      CONNECT_PLUGIN_PATH: /kafka/connect
    
    # ============================================
    # DOCKER LOGGING DRIVER CONFIGURATION
    # ============================================
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "5"
        labels: "service=kafka-connect,component=debezium"
    
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8083/"]
      interval: 10s
      timeout: 10s
      retries: 20
      start_period: 120s
    
    networks:
      - replication-network
    deploy:
      resources:
        limits:
          memory: 6G
          cpus: '2'
        reservations:
          memory: 4G
    restart: unless-stopped

  # ============================================
  # Django Web Application
  # ============================================
  django:
    build:
      context: ..
      dockerfile: Dockerfile
    container_name: django
    hostname: django
    depends_on:
      mysql:
        condition: service_healthy
      redis:
        condition: service_healthy
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy
    ports:
      - "8000:8000"
    environment:
      - DJANGO_SETTINGS_MODULE=jovoclient.settings
    env_file:
      - ../.env.docker
    volumes:
      - ..:/app
      - django-static:/app/staticfiles
      - django-media:/app/mediafiles
      - ../logs:/app/logs
    networks:
      - replication-network
    command: python manage.py runserver 0.0.0.0:8000
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8000/ || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s
    restart: unless-stopped

  # ============================================
  # Celery Worker - Task Executor
  # ============================================
  celery-worker:
    build:
      context: ..
      dockerfile: Dockerfile
    container_name: celery-worker
    hostname: celery-worker
    depends_on:
      - django
      - redis
    environment:
      - DJANGO_SETTINGS_MODULE=jovoclient.settings
    env_file:
      - ../.env.docker
    volumes:
      - ..:/app
      - ../logs:/app/logs
    networks:
      - replication-network
    command: celery -A jovoclient worker -l info -c 4 --max-tasks-per-child=100
    deploy:
      resources:
        limits:
          memory: 1G
    restart: unless-stopped

  # ============================================
  # Celery Beat - Periodic Tasks Scheduler
  # ============================================
  celery-beat:
    build:
      context: ..
      dockerfile: Dockerfile
    container_name: celery-beat
    hostname: celery-beat
    depends_on:
      - django
      - redis
      - celery-worker
    environment:
      - DJANGO_SETTINGS_MODULE=jovoclient.settings
    env_file:
      - ../.env.docker
    volumes:
      - ..:/app
      - ../logs:/app/logs
    networks:
      - replication-network
    command: celery -A jovoclient beat -l info
    restart: unless-stopped


volumes:
  mysql-data:
    driver: local
  redis-data:
    driver: local
  kafka1-data:
    driver: local
  kafka2-data:
    driver: local
  kafka3-data:
    driver: local
  django-static:
    driver: local
  django-media:
    driver: local
  celery-beat-schedule:
    driver: local


networks:
  replication-network:
    driver: bridge
    name: replication-network